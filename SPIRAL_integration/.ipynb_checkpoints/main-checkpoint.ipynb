{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb0ab30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.decomposition import PCA\n",
    "from operator import itemgetter\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import umap.umap_ as umap\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset,TensorDataset,DataLoader\n",
    "from torch.optim import Adam\n",
    "\n",
    "from pytorch_revgrad import RevGrad\n",
    "from model import *\n",
    "from utils import *\n",
    "from layers import MeanAggregator, LSTMAggregator, MaxPoolAggregator, MeanPoolAggregator,PoolAggregator\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# cuda=torch.cuda.is_available()\n",
    "# device=np.arange(torch.cuda.device_count())\n",
    "# if cuda:\n",
    "#     torch.cuda.set_device(device)\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6c2ed02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SPIRAL_integration:\n",
    "    def __init__(self,params,feat_file,edge_file,meta_file):\n",
    "        super(SPIRAL_integration, self).__init__()\n",
    "        \n",
    "        self.params = params\n",
    "        self.model=A_G_Combination_DA(self.params.AEdims, self.params.AEdimsR,self.params.GSdims,self.params.agg_class,self.params.num_samples,\n",
    "                                      self.params.zdim,self.params.znoise_dim,self.params.beta,self.params.CLdims,self.params.DIdims).cuda()\n",
    "        self.optim=Adam(self.model.parameters(),lr=self.params.lr,weight_decay=self.params.weight_decay)\n",
    "        self.epochs= self.params.epochs\n",
    "        self.BS=self.params.batch_size\n",
    "        self.dataset,self.Y,self.adj,self.dist,self.feat,self.meta=self.prepare_data(feat_file,edge_file,meta_file)\n",
    "        self.de_act=nn.Sigmoid() \n",
    "        self.sample_num=len(np.unique(self.Y))\n",
    "        if self.sample_num==2:\n",
    "            self.cl_act=nn.Sigmoid()\n",
    "        else:\n",
    "            self.cl_act=nn.Softmax(dim=1)\n",
    "\n",
    "        self.data_loader=DataLoader(dataset=self.dataset, batch_size=self.BS,shuffle=True,num_workers=8,drop_last=True)\n",
    "        self.unsupervised_loss=UnsupervisedLoss(self.adj.tolil().rows, self.dist, self.params.Q,N_WALKS,WALK_LEN,N_WALK_LEN,NUM_NEG)\n",
    "                                            \n",
    "    \n",
    "    def train(self):\n",
    "        self.model.train()\n",
    "        print('--------------------------------')\n",
    "        print('Training.')\n",
    "        with tqdm(total=self.epochs, file=sys.stdout) as pbar:\n",
    "            for epoch in np.arange(0,self.epochs):\n",
    "                total_loss=0.0;AE_loss=0.0;GS_loss=0.0;CLAS_loss=0;DISC_loss=0\n",
    "                t=time.time()\n",
    "                for (batch_idx, target_idx) in enumerate(self.data_loader):\n",
    "                    target_idx=target_idx[0]\n",
    "                    all_idx=np.asarray(list(self.unsupervised_loss.extend_nodes(target_idx.tolist())))\n",
    "                    all_layer,all_mapping=layer_map(all_idx.tolist(),self.adj,len(self.params.GSdims))\n",
    "                    all_rows=self.adj.tolil().rows[all_layer[0]]\n",
    "                    all_feature=torch.Tensor(self.feat.iloc[all_layer[0],:].values).float().cuda()\n",
    "                    all_embed,ae_out,clas_out,disc_out=self.model(all_feature,all_layer,all_mapping,all_rows,self.params.lamda,self.de_act,self.cl_act)\n",
    "                    [ae_embed,gs_embed,embed]=all_embed\n",
    "                    [x_bar,x]=ae_out\n",
    "                    gs_loss = self.unsupervised_loss.get_loss_xent(embed, all_idx)\n",
    "                    ae_loss=nn.BCELoss()(x_bar,x)\n",
    "                    if self.sample_num==2:\n",
    "                        true_batch=torch.Tensor(self.Y[all_layer[-1]]).cuda()\n",
    "                        clas_loss=nn.BCELoss()(clas_out,true_batch.reshape(-1,1))\n",
    "                        disc_loss=nn.BCELoss()(disc_out,true_batch.reshape(-1,1))\n",
    "                    else:\n",
    "                        true_batch=torch.Tensor(self.Y[all_layer[-1]]).long().cuda()\n",
    "                        clas_loss=nn.CrossEntropyLoss()(clas_out,true_batch)\n",
    "                        disc_loss=nn.CrossEntropyLoss()(disc_out,true_batch)\n",
    "                    loss=ae_loss*self.params.alpha1+gs_loss*self.params.alpha2+clas_loss*self.params.alpha3+disc_loss*self.params.alpha4\n",
    "\n",
    "                    self.optim.zero_grad()\n",
    "                    loss.backward()\n",
    "                    self.optim.step()\n",
    "                    total_loss+=loss.item()\n",
    "                    AE_loss+=ae_loss.item()\n",
    "                    GS_loss+=gs_loss.item()\n",
    "                    CLAS_loss+=clas_loss.item()\n",
    "                    DISC_loss+=disc_loss.item()\n",
    "\n",
    "                aa=(batch_idx+1)    \n",
    "                pbar.set_description('processed: %d' % (1 + epoch))\n",
    "                pbar.set_postfix(total_loss=total_loss/aa,GS_loss=GS_loss/aa,CLAS_loss=CLAS_loss/aa,DISC_loss=DISC_loss/aa)\n",
    "                pbar.update(1)    \n",
    "    def save_model(self):\n",
    "        torch.save(self.model.state_dict(),self.params.model_file)\n",
    "        print('Saving model to %s' % self.params.model_file)\n",
    "        \n",
    "    def load_model(self):\n",
    "        saved_state_dict = torch.load(self.params.model_file)\n",
    "        self.model.load_state_dict(saved_state_dict['state_dict'])\n",
    "        print('Loading model from %s' % self.params.model_file)\n",
    "        \n",
    "    def prepare_data(self,feat_file,edge_file,meta_file,SEP=','):\n",
    "        dataset,feat,adj,dist=load_data(feat_file,edge_file,SEP,N_WALKS,WALK_LEN,N_WALK_LEN,NUM_NEG)\n",
    "        x=minmax_scale(feat.values,axis=1)\n",
    "        feat=pd.DataFrame(x,index=feat.index,columns=feat.columns)\n",
    "        meta=pd.read_csv(meta_file[0],header=0,index_col=0)\n",
    "        for i in np.arange(1,len(meta_file)):\n",
    "            meta=pd.concat((meta,pd.read_csv(meta_file[i],header=0,index_col=0)),axis=0)\n",
    "        meta=meta.values\n",
    "        ub=np.unique(meta[:,1])\n",
    "        Y=np.zeros(meta.shape[0])\n",
    "        for i in range(len(ub)):\n",
    "            Y[np.where(meta[:,1]==ub[i])[0]]=i\n",
    "        return dataset,Y,adj,dist,feat,meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b201123e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
