{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6acce9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ot\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09bb76a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl_divergence_backend(X, Y):\n",
    "    \"\"\"\n",
    "    Returns pairwise KL divergence (over all pairs of samples) of two matrices X and Y.\n",
    "    \n",
    "    Takes advantage of POT backend to speed up computation.\n",
    "    \n",
    "    Args:\n",
    "        X: np array with dim (n_samples by n_features)\n",
    "        Y: np array with dim (m_samples by n_features)\n",
    "    \n",
    "    Returns:\n",
    "        D: np array with dim (n_samples by m_samples). Pairwise KL divergence matrix.\n",
    "    \"\"\"\n",
    "    assert X.shape[1] == Y.shape[1], \"X and Y do not have the same number of features.\"\n",
    "\n",
    "    nx = ot.backend.get_backend(X,Y)\n",
    "    \n",
    "    X = X/nx.sum(X,axis=1, keepdims=True)\n",
    "    Y = Y/nx.sum(Y,axis=1, keepdims=True)\n",
    "    log_X = nx.log(X)\n",
    "    log_Y = nx.log(Y)\n",
    "    X_log_X = nx.einsum('ij,ij->i',X,log_X)\n",
    "    X_log_X = nx.reshape(X_log_X,(1,X_log_X.shape[0]))\n",
    "    D = X_log_X.T - nx.dot(X,log_Y.T)\n",
    "    return nx.to_numpy(D)\n",
    "\n",
    "def f(G):\n",
    "    return ot.gromov.gwloss(constC, hC1, hC2, G)\n",
    "\n",
    "def df(G):\n",
    "    return ot.gromov.gwggrad(constC, hC1, hC2, G)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60f405d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dissimilarity='euc'\n",
    "norm=False\n",
    "alpha=0.8\n",
    "loss_fun='square_loss'\n",
    "backend=ot.backend.NumpyBackend()\n",
    "nx=backend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ac0ab0",
   "metadata": {},
   "source": [
    "simulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f426f081",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs=\"/data02/tguo/space_batch_effect/simulate/gtt_output/coordinate_file/\"\n",
    "batch_sim=\"_1\"\n",
    "types=\"_types4\"\n",
    "clusters=pd.read_csv(dirs+\"gtt_clusters\"+batch_sim+types+\".csv\",header=0,index_col=0,sep=\",\")\n",
    "ub=np.unique(clusters['batch'])\n",
    "for i in np.arange(1,len(ub)):\n",
    "    uc=np.intersect1d(clusters['clusters'][clusters['batch']==ub[0]],\n",
    "                     clusters['clusters'][clusters['batch']==ub[i]])\n",
    "    for clust in uc:\n",
    "        embed1=pd.read_csv(dirs+\"embed_\"+ub[0]+\"_\"+str(clust)+batch_sim+types+\".csv\",header=0,index_col=0,sep=\",\")\n",
    "        embed2=pd.read_csv(dirs+\"embed_\"+ub[i]+\"_\"+str(clust)+batch_sim+types+\".csv\",header=0,index_col=0,sep=\",\")\n",
    "        coord1=pd.read_csv(dirs+\"coord_\"+ub[0]+\"_\"+str(clust)+batch_sim+types+\".csv\",header=0,index_col=0,sep=\",\")\n",
    "        coord2=pd.read_csv(dirs+\"coord_\"+ub[i]+\"_\"+str(clust)+batch_sim+types+\".csv\",header=0,index_col=0,sep=\",\")\n",
    "        coord1=coord1.loc[embed1.index,:]\n",
    "        coord2=coord2.loc[embed2.index,:]\n",
    "        ###每个batch内部spot的空间距离####\n",
    "        a=np.float64(nx.from_numpy(coord1.values[:,:2]))\n",
    "        b=np.float64(nx.from_numpy(coord2.values[:,:2]))\n",
    "        D1=ot.dist(a,a, metric='euclidean')\n",
    "        D2=ot.dist(b,b, metric='euclidean')\n",
    "        if norm:\n",
    "            D1 /= nx.min(D1[D1>0])\n",
    "            D2 /= nx.min(D2[D2>0])\n",
    "        ####两个batch spot的低维表示的距离#####\n",
    "        X1,X2 = nx.from_numpy(embed1.values), nx.from_numpy(embed2.values)\n",
    "        if dissimilarity.lower()=='euclidean' or dissimilarity.lower()=='euc':\n",
    "            M = ot.dist(X1,X2)\n",
    "        else:\n",
    "            s1 = X1 + 0.01\n",
    "            s2 = X2 + 0.01\n",
    "            M = kl_divergence_backend(s1, s2)\n",
    "            M = nx.from_numpy(M)\n",
    "        ####每个batch的spot的分布#####\n",
    "        d1 = nx.ones((embed1.shape[0],))/embed1.shape[0]\n",
    "        d2 = nx.ones((embed2.shape[0],))/embed2.shape[0]\n",
    "        ####计算mapping#####\n",
    "        constC, hC1, hC2 = ot.gromov.init_matrix(D1, D2, d1, d2, loss_fun)\n",
    "        G0 = d1[:, None] * d2[None, :]\n",
    "        res=ot.gromov.cg(d1, d2, (1 - alpha) * M, alpha, f, df, G0, armijo=False, C1=D1, C2=D2, constC=constC)\n",
    "        pi=pd.DataFrame(res,index=embed1.index,columns=embed2.index)\n",
    "        pi.to_csv(dirs+\"gwd_pi_\"+ub[0]+\"_\"+ub[i]+\"_\"+str(clust)+batch_sim+types+\".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d523fe",
   "metadata": {},
   "source": [
    "DLPFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "101c2501",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=0.8\n",
    "dirs=\"/data02/tguo/space_batch_effect/human_DLPFC_10x/gtt_output/coordinate_file/\"\n",
    "samples=np.array(['151507','151508','151509','151510','151669','151670','151671','151672','151673','151674','151675','151676'])\n",
    "samples=samples[[8,9,10,11]]\n",
    "flags=\"\"\n",
    "for i in samples:\n",
    "    flags=flags+\"_\"+i\n",
    "clusters=pd.read_csv(dirs+\"gtt_clusters\"+flags+\".csv\",header=0,index_col=0,sep=\",\")\n",
    "ub=np.unique(clusters['batch'])\n",
    "for i in np.arange(1,len(ub)):\n",
    "    uc=np.intersect1d(clusters['clusters'][clusters['batch']==ub[0]],\n",
    "                     clusters['clusters'][clusters['batch']==ub[i]])\n",
    "    for clust in uc:\n",
    "        embed1=pd.read_csv(dirs+\"embed_\"+str(ub[0])+\"_\"+str(clust)+flags+\".csv\",header=0,index_col=0,sep=\",\")\n",
    "        embed2=pd.read_csv(dirs+\"embed_\"+str(ub[i])+\"_\"+str(clust)+flags+\".csv\",header=0,index_col=0,sep=\",\")\n",
    "        coord1=pd.read_csv(dirs+\"coord_\"+str(ub[0])+\"_\"+str(clust)+flags+\".csv\",header=0,index_col=0,sep=\",\")\n",
    "        coord2=pd.read_csv(dirs+\"coord_\"+str(ub[i])+\"_\"+str(clust)+flags+\".csv\",header=0,index_col=0,sep=\",\")\n",
    "        coord1=coord1.loc[embed1.index,:]\n",
    "        coord2=coord2.loc[embed2.index,:]\n",
    "        ###每个batch内部spot的空间距离####\n",
    "        a=np.float64(nx.from_numpy(coord1.values[:,:2]))\n",
    "        b=np.float64(nx.from_numpy(coord2.values[:,:2]))\n",
    "        D1=ot.dist(a,a, metric='euclidean')\n",
    "        D2=ot.dist(b,b, metric='euclidean')\n",
    "        if norm:\n",
    "            D1 /= nx.min(D1[D1>0])\n",
    "            D2 /= nx.min(D2[D2>0])\n",
    "        ####两个batch spot的低维表示的距离#####\n",
    "        X1,X2 = nx.from_numpy(embed1.values), nx.from_numpy(embed2.values)\n",
    "        if dissimilarity.lower()=='euclidean' or dissimilarity.lower()=='euc':\n",
    "            M = ot.dist(X1,X2)\n",
    "        else:\n",
    "            s1 = X1 + 0.01\n",
    "            s2 = X2 + 0.01\n",
    "            M = kl_divergence_backend(s1, s2)\n",
    "            M = nx.from_numpy(M)\n",
    "        ####每个batch的spot的分布#####\n",
    "        d1 = nx.ones((embed1.shape[0],))/embed1.shape[0]\n",
    "        d2 = nx.ones((embed2.shape[0],))/embed2.shape[0]\n",
    "        ####计算mapping#####\n",
    "        constC, hC1, hC2 = ot.gromov.init_matrix(D1, D2, d1, d2, loss_fun)\n",
    "        G0 = d1[:, None] * d2[None, :]\n",
    "        res=ot.gromov.cg(d1, d2, (1 - alpha) * M, alpha, f, df, G0, armijo=False, C1=D1, C2=D2, constC=constC)\n",
    "        pi=pd.DataFrame(res,index=embed1.index,columns=embed2.index)\n",
    "        pi.to_csv(dirs+\"gwd_pi_\"+str(ub[0])+\"_\"+str(ub[i])+\"_\"+str(clust)+flags+\".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7797a0dd",
   "metadata": {},
   "source": [
    "mouse brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d739f485",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs=\"/data02/tguo/space_batch_effect/mouse_brain/gtt_output/coordinate_file/\"\n",
    "samples=['anterior1','anterior2']\n",
    "flags=\"\"\n",
    "for i in samples:\n",
    "    flags=flags+\"_\"+i\n",
    "clusters=pd.read_csv(dirs+\"gtt_clusters\"+flags+\".csv\",header=0,index_col=0,sep=\",\")\n",
    "ub=np.unique(clusters['batch'])\n",
    "for i in np.arange(1,len(ub)):\n",
    "    uc=np.intersect1d(clusters['clusters'][clusters['batch']==ub[0]],\n",
    "                     clusters['clusters'][clusters['batch']==ub[i]])\n",
    "    for clust in uc:\n",
    "        embed1=pd.read_csv(dirs+\"embed_\"+str(ub[0])+\"_\"+str(clust)+flags+\".csv\",header=0,index_col=0,sep=\",\")\n",
    "        embed2=pd.read_csv(dirs+\"embed_\"+str(ub[i])+\"_\"+str(clust)+flags+\".csv\",header=0,index_col=0,sep=\",\")\n",
    "        coord1=pd.read_csv(dirs+\"coord_\"+str(ub[0])+\"_\"+str(clust)+flags+\".csv\",header=0,index_col=0,sep=\",\")\n",
    "        coord2=pd.read_csv(dirs+\"coord_\"+str(ub[i])+\"_\"+str(clust)+flags+\".csv\",header=0,index_col=0,sep=\",\")\n",
    "        coord1=coord1.loc[embed1.index,:]\n",
    "        coord2=coord2.loc[embed2.index,:]\n",
    "        ###每个batch内部spot的空间距离####\n",
    "        a=np.float64(nx.from_numpy(coord1.values[:,:2]))\n",
    "        b=np.float64(nx.from_numpy(coord2.values[:,:2]))\n",
    "        D1=ot.dist(a,a, metric='euclidean')\n",
    "        D2=ot.dist(b,b, metric='euclidean')\n",
    "        if norm:\n",
    "            D1 /= nx.min(D1[D1>0])\n",
    "            D2 /= nx.min(D2[D2>0])\n",
    "        ####两个batch spot的低维表示的距离#####\n",
    "        X1,X2 = nx.from_numpy(embed1.values), nx.from_numpy(embed2.values)\n",
    "        if dissimilarity.lower()=='euclidean' or dissimilarity.lower()=='euc':\n",
    "            M = ot.dist(X1,X2)\n",
    "        else:\n",
    "            s1 = X1 + 0.01\n",
    "            s2 = X2 + 0.01\n",
    "            M = kl_divergence_backend(s1, s2)\n",
    "            M = nx.from_numpy(M)\n",
    "        ####每个batch的spot的分布#####\n",
    "        d1 = nx.ones((embed1.shape[0],))/embed1.shape[0]\n",
    "        d2 = nx.ones((embed2.shape[0],))/embed2.shape[0]\n",
    "        ####计算mapping#####\n",
    "        constC, hC1, hC2 = ot.gromov.init_matrix(D1, D2, d1, d2, loss_fun)\n",
    "        G0 = d1[:, None] * d2[None, :]\n",
    "        res=ot.gromov.cg(d1, d2, (1 - alpha) * M, alpha, f, df, G0, armijo=False, C1=D1, C2=D2, constC=constC)\n",
    "        pi=pd.DataFrame(res,index=embed1.index,columns=embed2.index)\n",
    "        pi.to_csv(dirs+\"gwd_pi_\"+str(ub[0])+\"_\"+str(ub[i])+\"_\"+str(clust)+flags+\".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3887208e",
   "metadata": {},
   "source": [
    "10x 冠状面"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f09ea8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=0.8\n",
    "dirs=\"/data02/tguo/space_batch_effect/Hippo/gtt_output/coordinate_file/\"\n",
    "samples=['10X_Normal','10X_DAPI','10X_FFPE']\n",
    "flags=\"\"\n",
    "for i in samples:\n",
    "    flags=flags+\"_\"+i\n",
    "clusters=pd.read_csv(dirs+\"gtt_clusters\"+flags+\".csv\",header=0,index_col=0,sep=\",\")\n",
    "ub=np.unique(clusters['batch'])\n",
    "ub=['10X_Normal','10X_DAPI','10X_FFPE']\n",
    "for i in np.arange(1,len(ub)):\n",
    "    uc=np.intersect1d(clusters['clusters'][clusters['batch']==ub[0]],\n",
    "                     clusters['clusters'][clusters['batch']==ub[i]])\n",
    "    for clust in uc:\n",
    "        embed1=pd.read_csv(dirs+\"embed_\"+str(ub[0])+\"_\"+str(clust)+flags+\".csv\",header=0,index_col=0,sep=\",\")\n",
    "        embed2=pd.read_csv(dirs+\"embed_\"+str(ub[i])+\"_\"+str(clust)+flags+\".csv\",header=0,index_col=0,sep=\",\")\n",
    "        coord1=pd.read_csv(dirs+\"coord_\"+str(ub[0])+\"_\"+str(clust)+flags+\".csv\",header=0,index_col=0,sep=\",\")\n",
    "        coord2=pd.read_csv(dirs+\"coord_\"+str(ub[i])+\"_\"+str(clust)+flags+\".csv\",header=0,index_col=0,sep=\",\")\n",
    "        coord1=coord1.loc[embed1.index,:]\n",
    "        coord2=coord2.loc[embed2.index,:]\n",
    "        ###每个batch内部spot的空间距离####\n",
    "        a=np.float64(nx.from_numpy(coord1.values[:,:2]))\n",
    "        b=np.float64(nx.from_numpy(coord2.values[:,:2]))\n",
    "        D1=ot.dist(a,a, metric='euclidean')\n",
    "        D2=ot.dist(b,b, metric='euclidean')\n",
    "        if norm:\n",
    "            D1 /= nx.min(D1[D1>0])\n",
    "            D2 /= nx.min(D2[D2>0])\n",
    "        ####两个batch spot的低维表示的距离#####\n",
    "        X1,X2 = nx.from_numpy(embed1.values), nx.from_numpy(embed2.values)\n",
    "        if dissimilarity.lower()=='euclidean' or dissimilarity.lower()=='euc':\n",
    "            M = ot.dist(X1,X2)\n",
    "        else:\n",
    "            s1 = X1 + 0.01\n",
    "            s2 = X2 + 0.01\n",
    "            M = kl_divergence_backend(s1, s2)\n",
    "            M = nx.from_numpy(M)\n",
    "        ####每个batch的spot的分布#####\n",
    "        d1 = nx.ones((embed1.shape[0],))/embed1.shape[0]\n",
    "        d2 = nx.ones((embed2.shape[0],))/embed2.shape[0]\n",
    "        ####计算mapping#####\n",
    "        constC, hC1, hC2 = ot.gromov.init_matrix(D1, D2, d1, d2, loss_fun)\n",
    "        G0 = d1[:, None] * d2[None, :]\n",
    "        res=ot.gromov.cg(d1, d2, (1 - alpha) * M, alpha, f, df, G0, armijo=False, C1=D1, C2=D2, constC=constC)\n",
    "        pi=pd.DataFrame(res,index=embed1.index,columns=embed2.index)\n",
    "        pi.to_csv(dirs+\"gwd_pi_\"+str(ub[0])+\"_\"+str(ub[i])+\"_\"+str(clust)+flags+\".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3ce578",
   "metadata": {},
   "source": [
    "mouse ob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1ba8c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=0.1\n",
    "dirs=\"/data02/tguo/space_batch_effect/mouse_OB/gtt_output/coordinate_file/\"\n",
    "samples=['BGI','SlideV2','10X']\n",
    "# samples=['BGI','SlideV2','scRNA']\n",
    "flags=\"\"\n",
    "for i in samples:\n",
    "    flags=flags+\"_\"+i\n",
    "clusters=pd.read_csv(dirs+\"gtt_clusters\"+flags+\".csv\",header=0,index_col=0,sep=\",\")\n",
    "ub=np.unique(clusters['batch'])\n",
    "ub=samples\n",
    "for i in np.arange(1,len(ub)):\n",
    "    uc=np.intersect1d(clusters['clusters'][clusters['batch']==ub[0]],\n",
    "                     clusters['clusters'][clusters['batch']==ub[i]])\n",
    "    for clust in uc:\n",
    "        embed1=pd.read_csv(dirs+\"embed_\"+str(ub[0])+\"_\"+str(clust)+flags+\".csv\",header=0,index_col=0,sep=\",\")\n",
    "        embed2=pd.read_csv(dirs+\"embed_\"+str(ub[i])+\"_\"+str(clust)+flags+\".csv\",header=0,index_col=0,sep=\",\")\n",
    "        coord1=pd.read_csv(dirs+\"coord_\"+str(ub[0])+\"_\"+str(clust)+flags+\".csv\",header=0,index_col=0,sep=\",\")\n",
    "        coord2=pd.read_csv(dirs+\"coord_\"+str(ub[i])+\"_\"+str(clust)+flags+\".csv\",header=0,index_col=0,sep=\",\")\n",
    "        coord1=coord1.loc[embed1.index,:]\n",
    "        coord2=coord2.loc[embed2.index,:]\n",
    "        ###每个batch内部spot的空间距离####\n",
    "#         a=np.float64(nx.from_numpy(coord1.values[:,:2]))\n",
    "#         b=np.float64(nx.from_numpy(coord2.values[:,:2]))\n",
    "        a=np.float64(nx.from_numpy(coord1.values))\n",
    "        b=np.float64(nx.from_numpy(coord2.values))\n",
    "        D1=ot.dist(a,a, metric='euclidean')\n",
    "        D2=ot.dist(b,b, metric='euclidean')\n",
    "        if norm:\n",
    "            D1 /= nx.min(D1[D1>0])\n",
    "            D2 /= nx.min(D2[D2>0])\n",
    "        ####两个batch spot的低维表示的距离#####\n",
    "        X1,X2 = nx.from_numpy(embed1.values), nx.from_numpy(embed2.values)\n",
    "        if dissimilarity.lower()=='euclidean' or dissimilarity.lower()=='euc':\n",
    "            M = ot.dist(X1,X2)\n",
    "        else:\n",
    "            s1 = X1 + 0.01\n",
    "            s2 = X2 + 0.01\n",
    "            M = kl_divergence_backend(s1, s2)\n",
    "            M = nx.from_numpy(M)\n",
    "        ####每个batch的spot的分布#####\n",
    "        d1 = nx.ones((embed1.shape[0],))/embed1.shape[0]\n",
    "        d2 = nx.ones((embed2.shape[0],))/embed2.shape[0]\n",
    "        ####计算mapping#####\n",
    "        constC, hC1, hC2 = ot.gromov.init_matrix(D1, D2, d1, d2, loss_fun)\n",
    "        G0 = d1[:, None] * d2[None, :]\n",
    "        res=ot.gromov.cg(d1, d2, (1 - alpha) * M, alpha, f, df, G0, armijo=False, C1=D1, C2=D2, constC=constC,numItermax=100000,numItermaxEmd=1e6)\n",
    "        pi=pd.DataFrame(res,index=embed1.index,columns=embed2.index)\n",
    "        pi.to_csv(dirs+\"gwd_pi_\"+str(ub[0])+\"_\"+str(ub[i])+\"_\"+str(clust)+flags+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "823be578",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GTT_4</th>\n",
       "      <th>GTT_5</th>\n",
       "      <th>GTT_6</th>\n",
       "      <th>GTT_7</th>\n",
       "      <th>GTT_8</th>\n",
       "      <th>GTT_9</th>\n",
       "      <th>GTT_10</th>\n",
       "      <th>GTT_11</th>\n",
       "      <th>GTT_12</th>\n",
       "      <th>GTT_13</th>\n",
       "      <th>...</th>\n",
       "      <th>GTT_22</th>\n",
       "      <th>GTT_23</th>\n",
       "      <th>GTT_24</th>\n",
       "      <th>GTT_25</th>\n",
       "      <th>GTT_26</th>\n",
       "      <th>GTT_27</th>\n",
       "      <th>GTT_28</th>\n",
       "      <th>GTT_29</th>\n",
       "      <th>GTT_30</th>\n",
       "      <th>GTT_31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SlideV2-AAAAAGATCAGGTT</th>\n",
       "      <td>-0.170360</td>\n",
       "      <td>-0.153913</td>\n",
       "      <td>-0.139782</td>\n",
       "      <td>0.188074</td>\n",
       "      <td>0.109938</td>\n",
       "      <td>0.491718</td>\n",
       "      <td>-0.157277</td>\n",
       "      <td>0.179078</td>\n",
       "      <td>-0.620951</td>\n",
       "      <td>0.128879</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.377249</td>\n",
       "      <td>-0.152204</td>\n",
       "      <td>-0.101502</td>\n",
       "      <td>0.468256</td>\n",
       "      <td>0.475027</td>\n",
       "      <td>-0.438562</td>\n",
       "      <td>0.155265</td>\n",
       "      <td>0.160116</td>\n",
       "      <td>0.675001</td>\n",
       "      <td>0.451747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SlideV2-AAAAAGGTTTTGGG</th>\n",
       "      <td>0.081309</td>\n",
       "      <td>0.384900</td>\n",
       "      <td>-0.293209</td>\n",
       "      <td>0.188151</td>\n",
       "      <td>-0.338261</td>\n",
       "      <td>-0.274472</td>\n",
       "      <td>0.199760</td>\n",
       "      <td>-0.136510</td>\n",
       "      <td>0.187796</td>\n",
       "      <td>0.287287</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061433</td>\n",
       "      <td>0.043816</td>\n",
       "      <td>-0.238022</td>\n",
       "      <td>0.010100</td>\n",
       "      <td>0.052646</td>\n",
       "      <td>-0.206263</td>\n",
       "      <td>0.071546</td>\n",
       "      <td>-0.026444</td>\n",
       "      <td>-0.211838</td>\n",
       "      <td>-0.302042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SlideV2-AAAAATCGTCGCAC</th>\n",
       "      <td>-0.452554</td>\n",
       "      <td>0.560075</td>\n",
       "      <td>0.160644</td>\n",
       "      <td>0.703167</td>\n",
       "      <td>0.163454</td>\n",
       "      <td>-0.084037</td>\n",
       "      <td>-0.249380</td>\n",
       "      <td>0.158641</td>\n",
       "      <td>0.478881</td>\n",
       "      <td>0.029622</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082859</td>\n",
       "      <td>-0.536301</td>\n",
       "      <td>-0.126102</td>\n",
       "      <td>-0.071094</td>\n",
       "      <td>0.604978</td>\n",
       "      <td>0.045158</td>\n",
       "      <td>-0.103886</td>\n",
       "      <td>-0.058465</td>\n",
       "      <td>0.364410</td>\n",
       "      <td>0.265119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SlideV2-AAAAATTCTAAGTA</th>\n",
       "      <td>0.030323</td>\n",
       "      <td>0.218073</td>\n",
       "      <td>0.254941</td>\n",
       "      <td>0.125699</td>\n",
       "      <td>-0.161013</td>\n",
       "      <td>-0.191530</td>\n",
       "      <td>-0.416796</td>\n",
       "      <td>0.041352</td>\n",
       "      <td>0.127006</td>\n",
       "      <td>0.376724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.205280</td>\n",
       "      <td>0.134790</td>\n",
       "      <td>0.059280</td>\n",
       "      <td>0.129645</td>\n",
       "      <td>0.185062</td>\n",
       "      <td>-0.098025</td>\n",
       "      <td>0.310435</td>\n",
       "      <td>-0.019416</td>\n",
       "      <td>0.155625</td>\n",
       "      <td>0.264185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SlideV2-AAAAATTCTGAACC</th>\n",
       "      <td>-0.293104</td>\n",
       "      <td>0.100765</td>\n",
       "      <td>0.073194</td>\n",
       "      <td>0.488853</td>\n",
       "      <td>0.268205</td>\n",
       "      <td>-0.226572</td>\n",
       "      <td>0.405138</td>\n",
       "      <td>-0.011226</td>\n",
       "      <td>0.043004</td>\n",
       "      <td>0.139730</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087892</td>\n",
       "      <td>0.215490</td>\n",
       "      <td>0.371550</td>\n",
       "      <td>-0.204795</td>\n",
       "      <td>0.323758</td>\n",
       "      <td>-0.133126</td>\n",
       "      <td>0.294960</td>\n",
       "      <td>0.139621</td>\n",
       "      <td>0.394841</td>\n",
       "      <td>0.688287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SlideV2-TTTTTGAATGTCAA</th>\n",
       "      <td>-0.400190</td>\n",
       "      <td>0.362623</td>\n",
       "      <td>-0.098748</td>\n",
       "      <td>0.354262</td>\n",
       "      <td>0.098753</td>\n",
       "      <td>0.297566</td>\n",
       "      <td>-0.086875</td>\n",
       "      <td>-0.207666</td>\n",
       "      <td>0.321166</td>\n",
       "      <td>0.041881</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.040839</td>\n",
       "      <td>-0.104181</td>\n",
       "      <td>0.350871</td>\n",
       "      <td>-0.128532</td>\n",
       "      <td>-0.089945</td>\n",
       "      <td>-0.038234</td>\n",
       "      <td>-0.153584</td>\n",
       "      <td>0.160341</td>\n",
       "      <td>-0.052390</td>\n",
       "      <td>-0.195149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SlideV2-TTTTTTATTTTTTT</th>\n",
       "      <td>0.081960</td>\n",
       "      <td>0.215202</td>\n",
       "      <td>0.062646</td>\n",
       "      <td>0.142394</td>\n",
       "      <td>0.152964</td>\n",
       "      <td>-0.084917</td>\n",
       "      <td>0.387747</td>\n",
       "      <td>0.016497</td>\n",
       "      <td>-0.500035</td>\n",
       "      <td>0.107720</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.084059</td>\n",
       "      <td>0.192300</td>\n",
       "      <td>0.234828</td>\n",
       "      <td>-0.300199</td>\n",
       "      <td>0.098774</td>\n",
       "      <td>-0.389207</td>\n",
       "      <td>-0.302599</td>\n",
       "      <td>0.013265</td>\n",
       "      <td>-0.015795</td>\n",
       "      <td>0.000787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SlideV2-TTTTTTTTGCTAAC</th>\n",
       "      <td>0.223886</td>\n",
       "      <td>0.409774</td>\n",
       "      <td>0.010514</td>\n",
       "      <td>0.750321</td>\n",
       "      <td>-0.145308</td>\n",
       "      <td>-0.057763</td>\n",
       "      <td>0.163303</td>\n",
       "      <td>-0.199252</td>\n",
       "      <td>-0.155199</td>\n",
       "      <td>0.283754</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.257665</td>\n",
       "      <td>0.204354</td>\n",
       "      <td>0.289818</td>\n",
       "      <td>-0.185497</td>\n",
       "      <td>0.543484</td>\n",
       "      <td>-0.279441</td>\n",
       "      <td>-0.060972</td>\n",
       "      <td>0.226209</td>\n",
       "      <td>0.360027</td>\n",
       "      <td>-0.038424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SlideV2-TTTTTTTTTATACT</th>\n",
       "      <td>-0.240303</td>\n",
       "      <td>-0.026589</td>\n",
       "      <td>0.151231</td>\n",
       "      <td>-0.271260</td>\n",
       "      <td>0.101614</td>\n",
       "      <td>0.010893</td>\n",
       "      <td>-0.368306</td>\n",
       "      <td>0.129474</td>\n",
       "      <td>0.600429</td>\n",
       "      <td>-0.037006</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071060</td>\n",
       "      <td>0.312544</td>\n",
       "      <td>-0.571222</td>\n",
       "      <td>0.023424</td>\n",
       "      <td>-0.073096</td>\n",
       "      <td>0.247364</td>\n",
       "      <td>0.197792</td>\n",
       "      <td>0.014575</td>\n",
       "      <td>-1.198060</td>\n",
       "      <td>-0.281605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SlideV2-TTTTTTTTTTGTCT</th>\n",
       "      <td>-0.241389</td>\n",
       "      <td>-0.488809</td>\n",
       "      <td>0.071416</td>\n",
       "      <td>0.091612</td>\n",
       "      <td>0.267377</td>\n",
       "      <td>0.414567</td>\n",
       "      <td>0.273808</td>\n",
       "      <td>-0.156993</td>\n",
       "      <td>0.190330</td>\n",
       "      <td>0.209755</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.150524</td>\n",
       "      <td>0.079740</td>\n",
       "      <td>0.082908</td>\n",
       "      <td>0.098877</td>\n",
       "      <td>0.311253</td>\n",
       "      <td>-0.109508</td>\n",
       "      <td>-0.331069</td>\n",
       "      <td>0.166201</td>\n",
       "      <td>-0.107782</td>\n",
       "      <td>-0.070445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2527 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           GTT_4     GTT_5     GTT_6     GTT_7     GTT_8  \\\n",
       "SlideV2-AAAAAGATCAGGTT -0.170360 -0.153913 -0.139782  0.188074  0.109938   \n",
       "SlideV2-AAAAAGGTTTTGGG  0.081309  0.384900 -0.293209  0.188151 -0.338261   \n",
       "SlideV2-AAAAATCGTCGCAC -0.452554  0.560075  0.160644  0.703167  0.163454   \n",
       "SlideV2-AAAAATTCTAAGTA  0.030323  0.218073  0.254941  0.125699 -0.161013   \n",
       "SlideV2-AAAAATTCTGAACC -0.293104  0.100765  0.073194  0.488853  0.268205   \n",
       "...                          ...       ...       ...       ...       ...   \n",
       "SlideV2-TTTTTGAATGTCAA -0.400190  0.362623 -0.098748  0.354262  0.098753   \n",
       "SlideV2-TTTTTTATTTTTTT  0.081960  0.215202  0.062646  0.142394  0.152964   \n",
       "SlideV2-TTTTTTTTGCTAAC  0.223886  0.409774  0.010514  0.750321 -0.145308   \n",
       "SlideV2-TTTTTTTTTATACT -0.240303 -0.026589  0.151231 -0.271260  0.101614   \n",
       "SlideV2-TTTTTTTTTTGTCT -0.241389 -0.488809  0.071416  0.091612  0.267377   \n",
       "\n",
       "                           GTT_9    GTT_10    GTT_11    GTT_12    GTT_13  ...  \\\n",
       "SlideV2-AAAAAGATCAGGTT  0.491718 -0.157277  0.179078 -0.620951  0.128879  ...   \n",
       "SlideV2-AAAAAGGTTTTGGG -0.274472  0.199760 -0.136510  0.187796  0.287287  ...   \n",
       "SlideV2-AAAAATCGTCGCAC -0.084037 -0.249380  0.158641  0.478881  0.029622  ...   \n",
       "SlideV2-AAAAATTCTAAGTA -0.191530 -0.416796  0.041352  0.127006  0.376724  ...   \n",
       "SlideV2-AAAAATTCTGAACC -0.226572  0.405138 -0.011226  0.043004  0.139730  ...   \n",
       "...                          ...       ...       ...       ...       ...  ...   \n",
       "SlideV2-TTTTTGAATGTCAA  0.297566 -0.086875 -0.207666  0.321166  0.041881  ...   \n",
       "SlideV2-TTTTTTATTTTTTT -0.084917  0.387747  0.016497 -0.500035  0.107720  ...   \n",
       "SlideV2-TTTTTTTTGCTAAC -0.057763  0.163303 -0.199252 -0.155199  0.283754  ...   \n",
       "SlideV2-TTTTTTTTTATACT  0.010893 -0.368306  0.129474  0.600429 -0.037006  ...   \n",
       "SlideV2-TTTTTTTTTTGTCT  0.414567  0.273808 -0.156993  0.190330  0.209755  ...   \n",
       "\n",
       "                          GTT_22    GTT_23    GTT_24    GTT_25    GTT_26  \\\n",
       "SlideV2-AAAAAGATCAGGTT -0.377249 -0.152204 -0.101502  0.468256  0.475027   \n",
       "SlideV2-AAAAAGGTTTTGGG  0.061433  0.043816 -0.238022  0.010100  0.052646   \n",
       "SlideV2-AAAAATCGTCGCAC  0.082859 -0.536301 -0.126102 -0.071094  0.604978   \n",
       "SlideV2-AAAAATTCTAAGTA  0.205280  0.134790  0.059280  0.129645  0.185062   \n",
       "SlideV2-AAAAATTCTGAACC  0.087892  0.215490  0.371550 -0.204795  0.323758   \n",
       "...                          ...       ...       ...       ...       ...   \n",
       "SlideV2-TTTTTGAATGTCAA -0.040839 -0.104181  0.350871 -0.128532 -0.089945   \n",
       "SlideV2-TTTTTTATTTTTTT -0.084059  0.192300  0.234828 -0.300199  0.098774   \n",
       "SlideV2-TTTTTTTTGCTAAC -0.257665  0.204354  0.289818 -0.185497  0.543484   \n",
       "SlideV2-TTTTTTTTTATACT -0.071060  0.312544 -0.571222  0.023424 -0.073096   \n",
       "SlideV2-TTTTTTTTTTGTCT -0.150524  0.079740  0.082908  0.098877  0.311253   \n",
       "\n",
       "                          GTT_27    GTT_28    GTT_29    GTT_30    GTT_31  \n",
       "SlideV2-AAAAAGATCAGGTT -0.438562  0.155265  0.160116  0.675001  0.451747  \n",
       "SlideV2-AAAAAGGTTTTGGG -0.206263  0.071546 -0.026444 -0.211838 -0.302042  \n",
       "SlideV2-AAAAATCGTCGCAC  0.045158 -0.103886 -0.058465  0.364410  0.265119  \n",
       "SlideV2-AAAAATTCTAAGTA -0.098025  0.310435 -0.019416  0.155625  0.264185  \n",
       "SlideV2-AAAAATTCTGAACC -0.133126  0.294960  0.139621  0.394841  0.688287  \n",
       "...                          ...       ...       ...       ...       ...  \n",
       "SlideV2-TTTTTGAATGTCAA -0.038234 -0.153584  0.160341 -0.052390 -0.195149  \n",
       "SlideV2-TTTTTTATTTTTTT -0.389207 -0.302599  0.013265 -0.015795  0.000787  \n",
       "SlideV2-TTTTTTTTGCTAAC -0.279441 -0.060972  0.226209  0.360027 -0.038424  \n",
       "SlideV2-TTTTTTTTTATACT  0.247364  0.197792  0.014575 -1.198060 -0.281605  \n",
       "SlideV2-TTTTTTTTTTGTCT -0.109508 -0.331069  0.166201 -0.107782 -0.070445  \n",
       "\n",
       "[2527 rows x 28 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coord2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c72c9a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd15bf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clust=0\n",
    "i=1\n",
    "embed1=pd.read_csv(dirs+\"embed_\"+str(ub[0])+\"_\"+str(clust)+flags+\".csv\",header=0,index_col=0,sep=\",\")\n",
    "embed2=pd.read_csv(dirs+\"embed_\"+str(ub[i])+\"_\"+str(clust)+flags+\".csv\",header=0,index_col=0,sep=\",\")\n",
    "coord1=pd.read_csv(dirs+\"coord_\"+str(ub[0])+\"_\"+str(clust)+flags+\".csv\",header=0,index_col=0,sep=\",\")\n",
    "coord2=pd.read_csv(dirs+\"coord_\"+str(ub[i])+\"_\"+str(clust)+flags+\".csv\",header=0,index_col=0,sep=\",\")\n",
    "coord1=coord1.loc[embed1.index,:]\n",
    "coord2=coord2.loc[embed2.index,:]\n",
    "###每个batch内部spot的空间距离####\n",
    "a=np.float64(nx.from_numpy(coord1.values[:,:2]))\n",
    "b=np.float64(nx.from_numpy(coord2.values[:,:2]))\n",
    "D1=ot.dist(a,a, metric='euclidean')\n",
    "D2=ot.dist(b,b, metric='euclidean')\n",
    "if norm:\n",
    "    D1 /= nx.min(D1[D1>0])\n",
    "    D2 /= nx.min(D2[D2>0])\n",
    "####两个batch spot的低维表示的距离#####\n",
    "X1,X2 = nx.from_numpy(embed1.values), nx.from_numpy(embed2.values)\n",
    "if dissimilarity.lower()=='euclidean' or dissimilarity.lower()=='euc':\n",
    "    M = ot.dist(X1,X2)\n",
    "else:\n",
    "    s1 = X1 + 0.01\n",
    "    s2 = X2 + 0.01\n",
    "    M = kl_divergence_backend(s1, s2)\n",
    "    M = nx.from_numpy(M)\n",
    "####每个batch的spot的分布#####\n",
    "d1 = nx.ones((embed1.shape[0],))/embed1.shape[0]\n",
    "d2 = nx.ones((embed2.shape[0],))/embed2.shape[0]\n",
    "# ####计算mapping#####\n",
    "constC, hC1, hC2 = ot.gromov.init_matrix(D1, D2, d1, d2, loss_fun)\n",
    "G0 = d1[:, None] * d2[None, :]\n",
    "# res=ot.gromov.cg(d1, d2, (1 - alpha) * M, alpha, f, df, G0, armijo=False, C1=D1, C2=D2, constC=constC)\n",
    "# pi=pd.DataFrame(res,index=embed1.index,columns=embed2.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "323e7ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=0.5\n",
    "res=ot.gromov.cg(d1, d2, (1 - alpha) * M, alpha, f, df, G0, armijo=False, C1=D1, C2=D2, constC=constC,numItermax=100000,numItermaxEmd=1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eacdbbd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64),)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(np.sum(res,axis=1)==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee736f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
